from steps import step_upload
import streamlit as st

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
# MODEL_NAME = "cointegrated/rut5-base"
# CACHE_DIR = "models"

def navigation_buttons():
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –∫–Ω–æ–ø–æ–∫ –Ω–∞–≤–∏–≥–∞—Ü–∏–∏ –≤ –≤–µ—Ä—Ö–Ω–µ–π —á–∞—Å—Ç–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
    col1, col2, col3 = st.columns([1, 3, 1])
    
    with col1:
        if st.session_state.step > 1:
            if st.button("‚Üê –ù–∞–∑–∞–¥", use_container_width=True):
                st.session_state.step -= 1
                st.rerun()
    
    with col3:
        allow_next = False
        if st.session_state.step == 1:
            # –û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è
            valid_selection = (
                st.session_state.date_col and 
                st.session_state.target_col and 
                st.session_state.date_col != st.session_state.target_col
            )
            allow_next = valid_selection and st.session_state.raw_df is not None

        if st.session_state.step == 1:
            if allow_next:
                if st.button("–î–∞–ª–µ–µ ‚Üí", type="primary", use_container_width=True):
                    st.session_state.step += 1
                    st.rerun()
            else:
                help_msg = ("–í—ã–±–µ—Ä–∏—Ç–µ —Ä–∞–∑–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã –¥–∞—Ç—ã –∏ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π" 
                           if st.session_state.date_col == st.session_state.target_col 
                           else "–ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –∏ –≤—ã–±–µ—Ä–∏—Ç–µ —Å—Ç–æ–ª–±—Ü—ã")
                st.button(
                    "–î–∞–ª–µ–µ ‚Üí", 
                    disabled=True, 
                    help=help_msg,
                    use_container_width=True
                )


def init_session_state():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è session state —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤"""
    defaults = {
        'step': 1,
        'raw_df': None,
        'processed_df': None,
        'original_columns': [],
        'current_columns': [],
        'temp_columns': [],
        'file_uploaded': False,
        'date_col': None,
        'target_col': None,
        'current_file': None
    }
    
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value


def main():
    st.set_page_config(page_title="Time-series analysis", page_icon="üìä", layout="wide")
    init_session_state()
    
    st.title("üìä –ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤")
    navigation_buttons()
    
    if st.session_state.step == 1:
        st.subheader("–®–∞–≥ 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
        step_upload.run_step()
    
    elif st.session_state.step == 2:
        st.session_state.date_col
        st.session_state.target_col

   


if __name__ == "__main__":
    main()

# # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
# @st.cache_resource
# def load_model():
#     tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, cache_dir=CACHE_DIR)
#     model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME, cache_dir=CACHE_DIR)
#     return tokenizer, model

# # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–æ–≤—ã—Ö –Ω–∞–∑–≤–∞–Ω–∏–π
# def generate_new_names(columns, context=""):
#     try:
#         tokenizer, model = load_model()
#         prompt = f"""
#         –ü–µ—Ä–µ–∏–º–µ–Ω—É–π –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ –≤ –ø–æ–Ω—è—Ç–Ω—ã–µ, —Å–æ—Ö—Ä–∞–Ω–∏–≤ –ø–æ—Ä—è–¥–æ–∫.
#         –ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}. –ò—Å—Ö–æ–¥–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è: {', '.join(columns)}.
#         –û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é.
#         –ù–æ–≤—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è:"""
        
#         inputs = tokenizer(
#             prompt,
#             return_tensors="pt",
#             max_length=512,
#             truncation=True,
#             padding="max_length"
#         )
        
#         outputs = model.generate(
#             inputs.input_ids,
#             max_length=50,
#             num_beams=5,
#             early_stopping=True
#         )
        
#         new_names = tokenizer.decode(outputs[0], skip_special_tokens=True)
#         new_names = re.sub(r"[^–∞-—è–ê-–Ø0-9,\-_\s]", "", new_names)
#         new_names = [name.strip().replace(' ', '_') for name in new_names.split(",")]
        
#         if len(new_names) != len(columns):
#             return columns
#         return new_names
    
#     except Exception as e:
#         st.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {str(e)}")
#         return columns